# ğŸ„ Taller de Aprendizaje AutomÃ¡tico No Supervisado con el Dataset de Setas

Este repositorio contiene un taller prÃ¡ctico orientado al aprendizaje automÃ¡tico **no supervisado**, usando tÃ©cnicas de **PCA** y **Clustering (KMeans)**, junto con una comparativa con un modelo supervisado (Random Forest).

Usaremos el **Mushroom Dataset**, un conjunto de datos muy conocido en el Ã¡mbito educativo que contiene informaciÃ³n sobre diferentes tipos de hongos, incluyendo su clasificaciÃ³n como **comestibles o venenosos**.

---

## ğŸ“‚ Dataset

Puedes obtener el dataset desde el siguiente enlace:

ğŸ”— [Mushroom Dataset - UCI Repository](https://archive.ics.uci.edu/ml/datasets/Mushroom)

- **Instancia:** Cada fila representa un hongo.
- **Variables:** Todas son **categÃ³ricas** (forma, color, olor, etc.).
- **Variable objetivo (`class`)**: Binaria â€” `e` (edible/comestible) o `p` (poisonous/venenoso).

---

## ğŸ§  Objetivos del taller

- Cargar y explorar un dataset categÃ³rico complejo.
- Tratar valores nulos y eliminar columnas no informativas.
- Codificar variables categÃ³ricas usando **One-Hot Encoding**.
- Reducir dimensionalidad con **PCA (AnÃ¡lisis de Componentes Principales)**.
- Aplicar **K-Means Clustering** para detectar estructuras ocultas en los datos.
- Comparar el rendimiento del modelo no supervisado con un modelo supervisado (**Random Forest**).

---

## ğŸ”§ TecnologÃ­as utilizadas

- Python
- Pandas / NumPy
- Seaborn / Matplotlib
- Scikit-learn (`PCA`, `KMeans`, `RandomForestClassifier`)

---

## ğŸ—‚ï¸ Contenido del notebook

### 1. ğŸ“¥ Carga y exploraciÃ³n de datos
- VisualizaciÃ³n general del dataset.
- Conteo de valores nulos y valores Ãºnicos por variable.
- EliminaciÃ³n de columnas constantes o poco informativas.

### 2. ğŸ§¼ Preprocesamiento
- ImputaciÃ³n o eliminaciÃ³n de valores faltantes.
- ConversiÃ³n de variables categÃ³ricas con **OneHotEncoder**.
- SeparaciÃ³n entre `X` (features) e `y` (class).

### 3. ğŸ§ª PCA (AnÃ¡lisis de Componentes Principales)
- ReducciÃ³n de dimensionalidad a 2 componentes.
- VisualizaciÃ³n de los datos en 2D.
- EvaluaciÃ³n visual de separabilidad.

### 4. ğŸŒ³ ClasificaciÃ³n supervisada (Random Forest)
- Entrenamiento de un modelo de clasificaciÃ³n.
- EvaluaciÃ³n con mÃ©tricas de precisiÃ³n.
- Estudio del impacto del nÃºmero de componentes en el rendimiento del modelo.

### 5. ğŸ” Clustering con K-Means
- DeterminaciÃ³n del nÃºmero Ã³ptimo de clusters (mÃ©todo del codo).
- Entrenamiento y visualizaciÃ³n de clusters.
- EvaluaciÃ³n de la correspondencia entre clusters y clases reales (sin usar las etiquetas).


---

## ğŸ“Š EvaluaciÃ³n  

Se considerarÃ¡n los siguientes criterios:  

Competencia:  Evaluar conjuntos de datos utilizando herramientas de anÃ¡lisis y de visualizaciÃ³n de datos
  
âœ… Uso y gestiÃ³n de formato .csv  
âœ… Limpieza y preprocesado de datos  
âœ… VisualizaciÃ³n de datos (seaborn, matplotlib, plotly)  
âœ… AnÃ¡lisis exploratorio detallado (EDA)  
âœ… Uso de tÃ©cnicas de preprocesado (normalizaciÃ³n, escalado, label encoder, one hot encoder)    
âœ… Uso de tÃ©cnicas avanzadas de limpieza de datos (eliminaciÃ³n de valores atÃ­picos, imputaciÃ³n de valores faltantes)  
âœ… Uso de tÃ©cnicas de reducciÃ³n de dimensionalidad (PCA, t-SNE)   
  

Competencia:  Aplicar algoritmos de aprendizaje automÃ¡tico segÃºn el problema, identificando y resolviendo problemas clÃ¡sicos de inteligencia artificial:

âœ… Seleccionar las variables que son Ãºtiles y las que no lo son  
âœ… Reconocer un caso de aprendizaje no supervisado   
âœ… Aplicar modelos de clustering  
âœ… Reconocer si es un problema de regresiÃ³n o de clasificaciÃ³n      
âœ… SeparaciÃ³n de datos en train/test  
âœ… Uso modelos de ensemble (RandomForest, GradientBoosting, AdaBoost, XGBoost, LightGBM)  
  
MÃ¡s detalles en: [roadmap-mad-ai-p4.coderf5.es](https://roadmap-mad-ai-p4.coderf5.es/)  






